weak_cq_path: "/nas/home/qasemi/CQplus/Outputs/process_ascent/matched_sentences.csv"
#cq_path: "/nas/home/qasemi/Mowgli-CoreQuisite/outputs/EvaluateBatch/MCQ-2000/BasicBenchmark/test.csv"
cq_path: "/nas/home/qasemi/CQplus/Outputs/RemoveSimplePNLI/test_filtered.csv"
mnli_path: "/nas/home/qasemi/CQplus/Outputs/Corpora/MNLI/multinli_1.0/multinli_1.0_train.jsonl"

model_setup:
  model_name: ""
  tuned_model_path:
  max_length: ${data_module.max_seq_length}

hardware:
  gpus: '3'
  cpu_limit: 16
#  distributed_backend: #'dp' # None

train_setup:
  do_train: false
  accumulate_grad_batches: 4

  max_epochs: 1
  limit_train_batches: 1.0
  val_check_interval: 1.0
  warmup_steps: 5

  learning_rate: 1e-05
  adam_epsilon: 1e-06
  weight_decay: 0.1
  beta1: 0.9
  beta2: 0.998

  batch_size: ${data_module.train_batch_size}

data_module:
  train_batch_size: 4 #4
  val_batch_size: 4
  preprocessing_batch_size: 100

  pad_to_max_length: false
  preprocessing_num_workers: 4
  overwrite_cache: false

  dataloader_num_workers: 4

  max_seq_length: 256


hydra:
  run:
    dir: /nas/home/qasemi/CQplus/Outputs/${hydra.job.name}


# Comparitibility configs
lm_module:
  model_name_or_path: ${model_setup.model_name}
  learning_rate: ${train_setup.learning_rate}
  adam_epsilon: ${train_setup.adam_epsilon}
  weight_decay: ${train_setup.weight_decay}
  adam_beta1: ${train_setup.beta1}
  adam_beta2: ${train_setup.beta2}

trainer_args:
  accumulate_grad_batches: ${train_setup.accumulate_grad_batches}
  limit_train_batches: ${train_setup.limit_train_batches}
